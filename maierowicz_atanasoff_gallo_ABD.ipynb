{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Skuerjuan/tp2-chona/blob/main/maierowicz_atanasoff_gallo_ABD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TP2 Seminario IA\n",
        "# Maierowicz, Atanasoff, Gallo\n",
        "---\n",
        "## ¿Deberían aceptar darle el préstamo?\n",
        "### (Esta vez con redes neuronales)"
      ],
      "metadata": {
        "id": "SKa3CIYfqcEn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0qF_V_87qQAS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesamiento\n",
        "\n",
        "data = \"https://raw.githubusercontent.com/Skuerjuan/tp1_chona/refs/heads/main/loan_data.csv\"\n",
        "df = pd.read_csv(data)\n",
        "\n",
        "categorical = [\"person_gender\", \"person_education\", \"person_home_ownership\", \"loan_intent\", \"previous_loan_defaults_on_file\"]\n",
        "\n",
        "ct = ColumnTransformer(transformers=[(\"cat\", OneHotEncoder(), categorical)], remainder=\"passthrough\")\n",
        "\n",
        "x = ct.fit_transform(df)\n",
        "\n",
        "feature_names = ct.get_feature_names_out()\n",
        "\n",
        "df = pd.DataFrame(x, columns=feature_names)\n",
        "df_x = df.drop(columns=\"remainder__loan_status\")\n",
        "df_y = df[\"remainder__loan_status\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "3N9btYiksSAt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deberia haber un hyperparam de cuantas layers hay en el medio y otro de cuanto es el n\n",
        "# otro más que sea el activation sería una buena idea (?)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(x_train.shape[1],)),\n",
        "    layers.Dense(15, activation=\"relu\"),\n",
        "    layers.Dense(2, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "TiqyuhyUtepv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "b7941be6-91c2-4a4b-c7f6-681fa6d761d7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m32\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m452\u001b[0m (1.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">452</span> (1.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m452\u001b[0m (1.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">452</span> (1.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyrWW8pxygtC",
        "outputId": "1c8887f6-dc84-4f73-bf23-ab3b9855b872"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7244 - loss: 274.0557\n",
            "Epoch 2/10\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 14.6131\n",
            "Epoch 3/10\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7384 - loss: 10.7784\n",
            "Epoch 4/10\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7518 - loss: 13.5533\n",
            "Epoch 5/10\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7550 - loss: 12.9888\n",
            "Epoch 6/10\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7664 - loss: 11.1872\n",
            "Epoch 7/10\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7743 - loss: 10.6865\n",
            "Epoch 8/10\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7830 - loss: 9.2744\n",
            "Epoch 9/10\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7866 - loss: 9.8469\n",
            "Epoch 10/10\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7827 - loss: 10.3636\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a47580fbad0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, batch_size=64, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "y_pred_probs = model.predict(x_test)\n",
        "y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "print(f'Precision: {precision_score(y_test, y_pred_labels)}\\n')\n",
        "print(f'Recall: {recall_score(y_test, y_pred_labels)}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVe16EYw3sXD",
        "outputId": "d9deca3b-98bb-47fd-b2ec-788ba1f318ae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 9.278127670288086\n",
            "Test accuracy: 0.8295555710792542\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Precision: 0.9327272727272727\n",
            "\n",
            "Recall: 0.25522388059701495\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluar el mejor set de hyperparams que quede al final\n",
        "# comparar con el tp anterior\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "EPOCHS = 10\n",
        "N_SPLITS = 5\n",
        "\n",
        "def model_with_params(layers_num: int, neurons_per_layer: int, activation: str = \"relu\"):\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Input(shape=(x_train.shape[1],)))\n",
        "  for i in range(layers_num):\n",
        "    model.add(layers.Dense(neurons_per_layer, activation=activation))\n",
        "  model.add(layers.Dense(2, activation=\"softmax\"))\n",
        "  model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "# Sacado de acá: https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-keras.md\n",
        "def kfold_validation(model_opts, kfold: KFold):\n",
        "  fold_no = 1\n",
        "  acc_per_fold = []\n",
        "  loss_per_fold = []\n",
        "  _df_x = df_x.to_numpy()\n",
        "  _df_y = df_y.to_numpy()\n",
        "  for train, test in kfold.split(df_x, df_y):\n",
        "#    model = model_with_params(layers_num=model_opts[0], neurons_per_layer=model_opts[1], activation=model_opts[2])\n",
        "    model = model_with_params(1, 1)\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "    model.fit(_df_x[train], _df_y[train], epochs=EPOCHS, verbose=1)\n",
        "    print(f'Evaluating...')\n",
        "    score = model.evaluate(_df_x[test], _df_y[test], verbose=1)\n",
        "    print(f'Done...')\n",
        "    acc_per_fold.append(score[1])\n",
        "    loss_per_fold.append(score[0])\n",
        "    fold_no += 1\n",
        "  return {\n",
        "      \"accuracy\": np.mean(acc_per_fold),\n",
        "      \"loss\": np.mean(loss_per_fold)\n",
        "  }\n",
        "\n",
        "modelos = [\n",
        "  # Probamos uno grande\n",
        "  [5, 15, \"relu\"],\n",
        "  # Probamos uno chico\n",
        "  [2, 5, \"relu\"],\n",
        "  # Los mismos pero con otra función de activación\n",
        "  [5, 15, \"sigmoid\"],\n",
        "  [2, 5, \"softplus\"],\n",
        "]\n",
        "\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "for model_params in modelos:\n",
        "  kfold_validation(model_params, kfold)"
      ],
      "metadata": {
        "id": "SYZ6-OoN6z0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29064669-d4a8-4fdf-aaa8-e947e430c870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for fold 1 ...\n",
            "Epoch 1/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7740 - loss: 0.6044\n",
            "Epoch 2/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7749 - loss: 0.5334\n",
            "Epoch 3/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7760 - loss: 0.5320\n",
            "Epoch 4/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7744 - loss: 0.5340\n",
            "Epoch 5/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7780 - loss: 0.5295\n",
            "Epoch 6/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7783 - loss: 0.5291\n",
            "Epoch 7/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7774 - loss: 0.5302\n",
            "Epoch 8/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7785 - loss: 0.5289\n",
            "Epoch 9/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7764 - loss: 0.5315\n",
            "Epoch 10/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7778 - loss: 0.5297\n",
            "Evaluating...\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7569 - loss: 0.5560\n",
            "Done...\n",
            "Training for fold 2 ...\n",
            "Epoch 1/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7266 - loss: 9.4385\n",
            "Epoch 2/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7773 - loss: 0.5363\n",
            "Epoch 3/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7736 - loss: 0.5351\n",
            "Epoch 4/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7778 - loss: 0.5298\n",
            "Epoch 5/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7770 - loss: 0.5307\n",
            "Epoch 6/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7743 - loss: 0.5341\n",
            "Epoch 7/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7764 - loss: 0.5314\n",
            "Epoch 8/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7748 - loss: 0.5335\n",
            "Epoch 9/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7739 - loss: 0.5346\n",
            "Epoch 10/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7768 - loss: 0.5310\n",
            "Evaluating...\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7730 - loss: 0.5357\n",
            "Done...\n",
            "Training for fold 3 ...\n",
            "Epoch 1/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7798 - loss: 0.6040\n",
            "Epoch 2/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7803 - loss: 0.5269\n",
            "Epoch 3/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7769 - loss: 0.5309\n",
            "Epoch 4/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7804 - loss: 0.5264\n",
            "Epoch 5/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7748 - loss: 0.5334\n",
            "Epoch 6/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7768 - loss: 0.5309\n",
            "Epoch 7/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7792 - loss: 0.5279\n",
            "Epoch 8/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7814 - loss: 0.5252\n",
            "Epoch 9/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7783 - loss: 0.5291\n",
            "Epoch 10/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7775 - loss: 0.5301\n",
            "Evaluating...\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7584 - loss: 0.5542\n",
            "Done...\n",
            "Training for fold 4 ...\n",
            "Epoch 1/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7798 - loss: 0.6041\n",
            "Epoch 2/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7742 - loss: 0.5342\n",
            "Epoch 3/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7808 - loss: 0.5260\n",
            "Epoch 4/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7787 - loss: 0.5286\n",
            "Epoch 5/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7790 - loss: 0.5283\n",
            "Epoch 6/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7798 - loss: 0.5272\n",
            "Epoch 7/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7817 - loss: 0.5249\n",
            "Epoch 8/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7795 - loss: 0.5276\n",
            "Epoch 9/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7777 - loss: 0.5299\n",
            "Epoch 10/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7770 - loss: 0.5308\n",
            "Evaluating...\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7553 - loss: 0.5584\n",
            "Done...\n",
            "Training for fold 5 ...\n",
            "Epoch 1/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7910 - loss: 1.9549\n",
            "Epoch 2/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7831 - loss: 0.5282\n",
            "Epoch 3/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7959 - loss: 0.5113\n",
            "Epoch 4/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7928 - loss: 0.5161\n",
            "Epoch 5/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7920 - loss: 0.5204\n",
            "Epoch 6/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7876 - loss: 0.5229\n",
            "Epoch 7/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7850 - loss: 0.5221\n",
            "Epoch 8/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7998 - loss: 0.5040\n",
            "Epoch 9/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8133 - loss: 0.4651\n",
            "Epoch 10/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8152 - loss: 0.4539\n",
            "Evaluating...\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7962 - loss: 0.4831\n",
            "Done...\n",
            "Training for fold 6 ...\n",
            "Epoch 1/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7149 - loss: 288.6591\n",
            "Epoch 2/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7753 - loss: 0.5350\n",
            "Epoch 3/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7775 - loss: 0.5301\n",
            "Epoch 4/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7758 - loss: 0.5322\n",
            "Epoch 5/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7752 - loss: 0.5330\n",
            "Epoch 6/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7800 - loss: 0.5269\n",
            "Epoch 7/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7781 - loss: 0.5293\n",
            "Epoch 8/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7767 - loss: 0.5311\n",
            "Epoch 9/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7768 - loss: 0.5309\n",
            "Epoch 10/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7795 - loss: 0.5276\n",
            "Evaluating...\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7422 - loss: 0.5743\n",
            "Done...\n",
            "Training for fold 7 ...\n",
            "Epoch 1/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7805 - loss: 0.6060\n",
            "Epoch 2/10\n",
            "\u001b[1m1266/1266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7766 - loss: 0.5313\n",
            "Epoch 3/10\n",
            "\u001b[1m 556/1266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7784 - loss: 0.5289"
          ]
        }
      ]
    }
  ]
}